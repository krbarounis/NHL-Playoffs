{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',100)\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the csv file that has all of our collected data from the two NHL APIs\n",
    "df = pd.read_csv('Final_NHL_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the index to our unique team/season IDs\n",
    "df.set_index('teamID_seasonID',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that are repeated from the two API calls (regular season and defense stats)\n",
    "df.drop(columns=['Unnamed: 0','wins_y','shootingPctg_y','ot','losses_y','faceoffsLost','faceoffsWon',\n",
    "                 'faceoffWinPctg','faceoffs','gamesPlayed_y'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column to reflect a team's win percentage for the season\n",
    "# this will be our target variable for our OLS model\n",
    "df['win_percentage']=df['wins_x']/df['gamesPlayed_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram and normal probability plot of our target variable to see distribution\n",
    "sns.distplot(df['win_percentage'], fit=stats.norm, bins=20, kde=False);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df['win_percentage'], plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of independent variables, removing variables which are strings\n",
    "features = features[1:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break the colums into groups to plot 4 on a row at a time\n",
    "n = 4\n",
    "row_groups= [features[i:i+n] for i in range(0, len(features), n) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scatter plots for every independent variable vs. our target variable\n",
    "for i in row_groups:\n",
    "    pp = sns.pairplot(data=df, y_vars=['win_percentage'],x_vars=i, kind=\"reg\", height=3)\n",
    "\n",
    "pp.savefig('Pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate distribution of specific variable which seems to have outliers\n",
    "sns_plot = sns.distplot(df['faceOffsWon'], axlabel = \"Number of Faceoffs Won by Team\",bins=30,color='g').set_title(\"Faceoff Distribution\")\n",
    "fig = sns_plot.get_figure()\n",
    "fig.savefig('FaceOff_dist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the rows associated with the identified outliers \n",
    "df[(df['faceOffsWon']>1200) & (df['faceOffsWon']<1600)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the rows shown above which refer to a season which had a partial lockout\n",
    "# as these values do not reflect a standard regular season in the NHL\n",
    "\n",
    "ixl = list(df.index)\n",
    "lockout = [i for i in ixl if '20122013' in i]\n",
    "df.drop(index=lockout,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate distribution for faceoffs won after removing outliers\n",
    "sns_plot = sns.distplot(df['faceOffsWon'], axlabel = \"Number of Faceoffs Won by Team\",bins=30,color='g').set_title(\"Faceoff Distribution\")\n",
    "fig = sns_plot.get_figure()\n",
    "fig.savefig('FaceOff_dist_no_outliers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create individual plots for certain variables after removing outliers\n",
    "plot = sns.pairplot(data=df, y_vars=['win_percentage'],\n",
    "             x_vars='shotsFor', kind=\"reg\", \n",
    "             height=4,aspect=1.5)\n",
    "plot.fig.suptitle('Correlation between total shot attempts and win percentage')\n",
    "# plot.axes.set_xlabel('Number of faceoffs lost in a season')\n",
    "plt.xlabel(\"Number of shot attempts in a season\")\n",
    "plt.ylabel('Win percentage')\n",
    "\n",
    "plot.savefig('Corr1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.pairplot(data=df, y_vars=['hits'],\n",
    "             x_vars='shotsFor', kind=\"reg\", \n",
    "             height=4,aspect=1.5)\n",
    "plot.fig.suptitle('Correlation between total hits attempts and win percentage')\n",
    "# plot.axes.set_xlabel('Number of faceoffs lost in a season')\n",
    "plt.xlabel(\"Number of hits in a season\")\n",
    "plt.ylabel('Win percentage')\n",
    "\n",
    "plot.savefig('Corr2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.pairplot(data=df, y_vars=['savePctg'],\n",
    "             x_vars='shotsFor', kind=\"reg\", \n",
    "             height=4,aspect=1.5)\n",
    "plot.fig.suptitle('Correlation between save percentage and win percentage')\n",
    "# plot.axes.set_xlabel('Number of faceoffs lost in a season')\n",
    "plt.xlabel(\"Goalie's save percentage\")\n",
    "plt.ylabel('Win percentage')\n",
    "\n",
    "plot.savefig('Corr4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check to make sure there are no missing values in the dataframe\n",
    "null_values = sns.heatmap(df.isnull(), cbar=False)\n",
    "fig = null_values.get_figure()\n",
    "fig.savefig('Null_values.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for a categorical variable, adding a 1\n",
    "# for the original 6 teams in the NHL, otherwise add a 0\n",
    "df['Original_6']=np.where(((df['teamFullName']=='Boston Bruins') | (df['teamFullName']=='Chicago Blackhawks') |\n",
    "                    (df['teamFullName']=='Detroit Red Wings') | (df['teamFullName']=='New York Rangers')\n",
    "                    | (df['teamFullName']=='Toronto Maple Leafs') | (df['teamFullName']=='Montreal Canadiens')),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an interaction variable that aims to measure\n",
    "# defensive strength of a team\n",
    "df['defensive_strength'] = df['hits']*df['takeaways']*df['penaltyKillPercentage']*df['shotsAllowed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new interaction variable which is a proxy for puck possession\n",
    "df['puck_possession']=(df['blockedShots']*df['shotsFor']*df['missedShots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CorrMtx(df, dropDuplicates = True):\n",
    "\n",
    "    # Your dataset is already a correlation matrix.\n",
    "    # If you have a dateset where you need to include the calculation\n",
    "    # of a correlation matrix, just uncomment the line below:\n",
    "    # df = df.corr()\n",
    "\n",
    "    # Exclude duplicate correlations by masking uper right values\n",
    "    if dropDuplicates:    \n",
    "        mask = np.zeros_like(df, dtype=np.bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set background color / chart style\n",
    "    sns.set_style(style = 'white')\n",
    "\n",
    "    # Set up  matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Add diverging colormap from red to blue\n",
    "    cmap = sns.diverging_palette(250, 10, as_cmap=True)\n",
    "\n",
    "    # Draw correlation plot with or without duplicates\n",
    "    if dropDuplicates:\n",
    "        sns.heatmap(df, mask=mask, cmap=cmap, \n",
    "                square=True,\n",
    "                linewidth=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "    else:\n",
    "        sns.heatmap(df, cmap=cmap, \n",
    "                square=True,\n",
    "                linewidth=.5, cbar_kws={\"shrink\": .5}, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a correlation on all of our variables\n",
    "# print the heat map \n",
    "corr = df.corr()\n",
    "CorrMtx(corr, dropDuplicates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate the independent variables that we want to run through our model\n",
    "features = ['faceOffWinPercentage',\n",
    "       'faceOffsWon', 'goalsAgainstPerGame', 'goalsPerGame',\n",
    "       'powerPlayPercentage', 'savePctg', 'shootingPctg_x',\n",
    "       'shotsAllowed', 'blockedShots', 'giveaways', 'goalsFor', \n",
    "        'missedShots', 'shotsFor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run our first test model using most of our features \n",
    "slr_model_1 = sm.OLS(endog=df['win_percentage'], exog=sm.add_constant(df[features])).fit()\n",
    "\n",
    "slr_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that shows the distribution of the residual values from a model\n",
    "# and creates a scattor plot of the residuals vs. the target variable\n",
    "def checkresiduals(df, target, sm_model):\n",
    "    # checking for our model - Homoscedasticity,  Independence of residuals\n",
    "    pred_val = sm_model.fittedvalues.copy()\n",
    "    true_val = df[target].values.copy()\n",
    "    residual = true_val - pred_val\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    ax1.hist(residual, density=True, bins=30)\n",
    "    ax2.scatter(df[target],residual)\n",
    "    ax2.set_title('Residual Scatterplot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the residuals of the first model\n",
    "checkresiduals(df, 'win_percentage', slr_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tune our independent variables by removing variables \n",
    "# with large p-values (indicating they do not have statistical significance)\n",
    "features = ['faceOffsLost', 'powerPlayOpportunities',\n",
    "            'savePctg', 'puck_possession']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a second test model\n",
    "# this model has a lower R-squared but now our variables\n",
    "# are all statistically significant\n",
    "slr_model_2 = sm.OLS(endog=df['win_percentage'], exog=sm.add_constant(df[features])).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the features so that our coefficients are on the same scale\n",
    "# and can be interpreted \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[features])\n",
    "scaled_features = scaler.transform(df[features])\n",
    "\n",
    "scaled_features_df = pd.DataFrame(scaled_features, columns=features, index=df.index)\n",
    "scaled_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a new model with same features from model 2 \n",
    "# but now the features have been scaled\n",
    "# R-squared should be the same as it was in model 2\n",
    "scaled_features_model_2= sm.OLS(endog=df['win_percentage'], exog=sm.add_constant(scaled_features_df)).fit()\n",
    "\n",
    "scaled_features_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we know that our features above returned an R-squared of .4\n",
    "# so let's try to do better\n",
    "# add in two more features, one for average goals against per game \n",
    "# and average goals for per game\n",
    "features = ['faceOffsLost', 'goalsAgainstPerGame','goalsPerGame',\n",
    "            'giveaways','savePctg', 'puck_possession']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the features prior to running the next model\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[features])\n",
    "scaled_features = scaler.transform(df[features])\n",
    "\n",
    "scaled_features_df = pd.DataFrame(scaled_features, columns=features, index=df.index)\n",
    "scaled_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the third model\n",
    "# the goal data has now increased the R-squared\n",
    "# and all of our p-values are significant\n",
    "slr_model_3 = sm.OLS(endog=df['win_percentage'], exog=sm.add_constant(scaled_features_df)).fit()\n",
    "\n",
    "slr_model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the residuals of our new third model\n",
    "checkresiduals(df, 'win_percentage', slr_model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we noticed additional outliers in the data\n",
    "# the NHL attempted to implement stronger rules against obstruction\n",
    "# so a variety of the data from the 2002 season is lower than the \n",
    "# remainder of the data\n",
    "\n",
    "# remove that season to check if it impacts our results\n",
    "ixl = list(df.index)\n",
    "lockout = [i for i in ixl if '20022003' in i]\n",
    "df_exclude2002 = df.drop(index=lockout,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exclude2002.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the features again with our smaller data set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_exclude2002[features])\n",
    "scaled_features = scaler.transform(df_exclude2002[features])\n",
    "\n",
    "scaled_features_df = pd.DataFrame(scaled_features, columns=features, index=df_exclude2002.index)\n",
    "scaled_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a model excluding the 2002 season\n",
    "scaled_features_model_exclude2002 = sm.OLS(endog=df['win_percentage'], exog=sm.add_constant(scaled_features_df)).fit()\n",
    "\n",
    "scaled_features_model_exclude2002.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkresiduals(df_exclude2002, 'win_percentage', scaled_features_model_exclude2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model immaterially impacted by removing the 2002 seaon\n",
    "# so we chose to keep that season's data in our final models (slr_model_2 and slr_model_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
